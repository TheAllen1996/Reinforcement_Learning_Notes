% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto, \emph{Reinforcement learning: An
  introduction}.\hskip 1em plus 0.5em minus 0.4em\relax MIT press, 2018.

\bibitem{HB}
J.~K. Blitzstein and J.~Hwang, \emph{Introduction to Probability}.\hskip 1em
  plus 0.5em minus 0.4em\relax Chapman and Hall/CRC, 2014.

\bibitem{robert2013monte}
C.~Robert and G.~Casella, \emph{Monte Carlo statistical methods}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer Science \& Business Media, 2013.

\bibitem{si252}
Z.~Shao, ``Si252 reinforcement learning,''
  \url{https://piazza.com/class/k5ug5osvzhp3z8}.

\bibitem{slivkins2019introduction}
A.~Slivkins \emph{et~al.}, ``Introduction to multi-armed bandits,''
  \emph{Foundations and Trends{\textregistered} in Machine Learning}, vol.~12,
  no. 1-2, pp. 1--286, 2019.

\bibitem{lattimore2018bandit}
T.~Lattimore and C.~Szepesv{\'a}ri, ``Bandit algorithms,'' \emph{preprint},
  p.~28, 2018.

\bibitem{liblog}
L.~Weng, ``{The Multi-Armed Bandit Problem and Its Solutions},''
  \url{https://lilianweng.github.io/lil-log/2018/01/23/the-multi-armed-bandit-problem-and-its-solutions.html}.

\bibitem{introRL}
B.~Zhou, ``Intro to reinforcement learning,''
  \url{https://github.com/zhoubolei/introRL}.

\bibitem{ucl_rl}
D.~Silver, ``Reinforcement learning,''
  \url{https://www.davidsilver.uk/teaching/}.

\bibitem{liblog-pga}
L.~Weng, ``{Policy Gradient Algorithms},''
  \url{https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html}.

\bibitem{schulman2015highdimensional}
J.~Schulman, P.~Moritz, S.~Levine, M.~Jordan, and P.~Abbeel, ``High-dimensional
  continuous control using generalized advantage estimation,'' 2015.

\bibitem{notes_GAE}
D.~Seita, ``{Notes on the Generalized Advantage Estimation Paper},''
  \url{https://danieltakeshi.github.io/2017/04/02/notes-on-the-generalized-advantage-estimation-paper/}.

\end{thebibliography}
